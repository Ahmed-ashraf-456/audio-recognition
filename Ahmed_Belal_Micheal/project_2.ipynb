{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import scipy \n",
    "import librosa\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy.signal import get_window\n",
    "import python_speech_features as mfcc\n",
    "from sklearn.mixture import GaussianMixture \n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feartures Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_features(file_path):\n",
    "\n",
    "#     x, sr = librosa.load(file_path)\n",
    "\n",
    "#     freqs = np.fft.fftfreq(x.size)\n",
    "\n",
    "#     def describe_freq(freqs):\n",
    "#         mean = np.mean(freqs)\n",
    "#         std = np.std(freqs) \n",
    "#         maxv = np.amax(freqs) \n",
    "#         minv = np.amin(freqs) \n",
    "#         median = np.median(freqs)\n",
    "#         skew = scipy.stats.skew(freqs)\n",
    "#         kurt = scipy.stats.kurtosis(freqs)\n",
    "#         q1 = np.quantile(freqs, 0.25)\n",
    "#         q3 = np.quantile(freqs, 0.75)\n",
    "#         mode = scipy.stats.mode(freqs)[0][0]\n",
    "#         iqr = scipy.stats.iqr(freqs)\n",
    "\n",
    "#         return [mean, std, maxv, minv, median, skew, kurt, q1, q3, mode, iqr]\n",
    "\n",
    "#     def rmse(x):\n",
    "#         return [np.sum(x**2)]\n",
    "\n",
    "#     def rmse2(x):\n",
    "#         return [np.sqrt(np.mean(x**2))]\n",
    "\n",
    "#     zero_crossings = [sum(librosa.zero_crossings(x, pad=False))]\n",
    "\n",
    "#     tempo = [librosa.beat.tempo(x)[0]]\n",
    "\n",
    "#     # mfcc=librosa.feature.mfcc(x)\n",
    "#     mfcc = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=1)\n",
    "\n",
    "\n",
    "\n",
    "#     hop_length = 512\n",
    "#     oenv      = librosa.onset.onset_strength(y=x, sr=sr, hop_length=hop_length)\n",
    "#     # tempogram = librosa.feature.tempogram(onset_envelope=oenv, sr=sr, hop_length=hop_length)\n",
    "#     spec_centroid = librosa.feature.spectral_centroid(x)[0]\n",
    "#     spectral_bandwidth=librosa.feature.spectral_bandwidth(x)[0]\n",
    "#     spectral_contrast=librosa.feature.spectral_contrast(x)[0]\n",
    "#     spectral_flatness=librosa.feature.spectral_flatness(x)[0]\n",
    "#     spectral_rolloff=librosa.feature.spectral_rolloff(x)[0]\n",
    "\n",
    "#     combined = np.hstack([describe_freq(freqs),rmse(x),rmse2(x),zero_crossings,tempo,mfcc[0],oenv,spec_centroid,spectral_bandwidth,\n",
    "#                         spectral_contrast, spectral_flatness, spectral_rolloff]) \n",
    "#     return combined\n",
    "\n",
    "# extract_features('./files/magdy/100.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MFCC Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta(array):\n",
    "\n",
    "    rows,cols = array.shape\n",
    "    print(rows)\n",
    "    print(cols)\n",
    "    deltas = np.zeros((rows,20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i-j < 0:\n",
    "                first =0\n",
    "            else:\n",
    "                first = i-j\n",
    "            if i+j > rows-1:\n",
    "                second = rows-1\n",
    "            else:\n",
    "                second = i+j \n",
    "            index.append((second,first))\n",
    "            j+=1\n",
    "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
    "    return deltas\n",
    "\n",
    "def extract_features(file_path):\n",
    "    audio , sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    mfcc_feature = mfcc.mfcc(audio,sample_rate, 0.025, 0.01,20,nfft = 1200, appendEnergy = True)    \n",
    "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
    "    print(mfcc_feature)\n",
    "    delta = calculate_delta(mfcc_feature)\n",
    "    \n",
    "    combined = np.hstack((mfcc_feature,delta))\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\SBME\\3rd year\\DSP\\repo final\\audio-recognition-2\\Ahmed_Belal_Micheal\n",
      "[[-1.73623492 -0.50451577  1.93144308 ...  2.67112852  0.37860671\n",
      "   0.01531219]\n",
      " [-0.94921178  0.12338125  1.48488123 ...  1.71902809  1.40020765\n",
      "   0.53952189]\n",
      " [-0.90534863  0.11268072  1.51496681 ...  1.54459365  1.78517215\n",
      "   0.72090379]\n",
      " ...\n",
      " [ 0.11314614 -0.11822816 -0.93656715 ...  1.24985524 -0.30926458\n",
      "  -0.14593034]\n",
      " [ 0.22226859 -0.10423302 -1.0165006  ...  0.48672734 -1.15411973\n",
      "  -0.46771513]\n",
      " [ 0.19594677 -0.10082724 -1.2645474  ...  0.72614696 -0.41650277\n",
      "  -0.36635967]]\n",
      "198\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\somakiko\\AppData\\Local\\Temp\\ipykernel_4564\\1728697229.py:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sentenceFeatures = np.array([chroma_stft,rmse,spec_cent,spec_bw,rolloff,zcr])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 2 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\SBME\\3rd year\\DSP\\repo final\\audio-recognition-2\\Ahmed_Belal_Micheal\\project_2.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20year/DSP/repo%20final/audio-recognition-2/Ahmed_Belal_Micheal/project_2.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m             features[name] \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20year/DSP/repo%20final/audio-recognition-2/Ahmed_Belal_Micheal/project_2.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m             samples[name] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20year/DSP/repo%20final/audio-recognition-2/Ahmed_Belal_Micheal/project_2.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         features[name] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack(extract_features(audio_path) )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20year/DSP/repo%20final/audio-recognition-2/Ahmed_Belal_Micheal/project_2.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         samples[name] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20year/DSP/repo%20final/audio-recognition-2/Ahmed_Belal_Micheal/project_2.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mif\u001b[39;00m noNames:\n",
      "\u001b[1;32md:\\SBME\\3rd year\\DSP\\repo final\\audio-recognition-2\\Ahmed_Belal_Micheal\\project_2.ipynb Cell 6\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20year/DSP/repo%20final/audio-recognition-2/Ahmed_Belal_Micheal/project_2.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m zcr \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mfeature\u001b[39m.\u001b[39mzero_crossing_rate(y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20year/DSP/repo%20final/audio-recognition-2/Ahmed_Belal_Micheal/project_2.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m sentenceFeatures \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([chroma_stft,rmse,spec_cent,spec_bw,rolloff,zcr])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20year/DSP/repo%20final/audio-recognition-2/Ahmed_Belal_Micheal/project_2.ipynb#W5sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m combined \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mhstack((mfcc_feature,delta,sentenceFeatures))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20year/DSP/repo%20final/audio-recognition-2/Ahmed_Belal_Micheal/project_2.ipynb#W5sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mreturn\u001b[39;00m combined\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\somakiko\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\shape_base.py:345\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39mconcatenate(arrs, \u001b[39m0\u001b[39m)\n\u001b[0;32m    344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 345\u001b[0m     \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 2 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "names = ['OTD','CTD','OTW','CTW']\n",
    "features = {}\n",
    "samples = {}\n",
    "# directory = './Speaker_Train_Data/'\n",
    "# for audio in os.listdir(directory):\n",
    "#     audio_path = directory + audio\n",
    "#     if 'Michael'\n",
    "\n",
    "# featuresMichael = []\n",
    "# featuresAhmed = []\n",
    "# featuresBelal = []\n",
    "# featuresOthers = []\n",
    "print(os.getcwd())\n",
    "directory = './Speaker_Train_Data/'\n",
    "for audio in os.listdir(directory):\n",
    "    audio_path = directory + audio\n",
    "    noNames = True\n",
    "    for name in names:\n",
    "        if name in audio:\n",
    "            noNames = False\n",
    "            if name not in features:\n",
    "                features[name] = []\n",
    "                samples[name] = 0\n",
    "            features[name] = np.vstack(extract_features(audio_path) )\n",
    "            samples[name] += 1\n",
    "    if noNames:\n",
    "        if 'others' not in features:\n",
    "            features['others'] = []\n",
    "            samples['others'] = 0\n",
    "        features['others'] = np.vstack(extract_features(audio_path))\n",
    "        samples['others'] += 1\n",
    "    print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for name,val in features.items():\n",
    "    models[name] = GaussianMixture(n_components = 6, max_iter = 2000, covariance_type='diag',n_init = 3)\n",
    "    models[name].fit(val)\n",
    "\n",
    "# michael_gmm = GaussianMixture(n_components = 6, max_iter = 2000, covariance_type='diag',n_init = 3)\n",
    "# michael_gmm.fit(featuresMichael)\n",
    "\n",
    "# belal_gmm = GaussianMixture(n_components = 6, max_iter = 2000, covariance_type='diag',n_init = 3)\n",
    "# belal_gmm.fit(featuresBelal)\n",
    "\n",
    "# ahmed_gmm = GaussianMixture(n_components = 6, max_iter = 2000, covariance_type='diag',n_init = 3)\n",
    "# ahmed_gmm.fit(featuresAhmed)\n",
    "\n",
    "# others_gmm = GaussianMixture(n_components = 6, max_iter = 2000, covariance_type='diag',n_init = 3)\n",
    "# others_gmm.fit(featuresOthers)\n",
    "\n",
    "# open_gmm = GaussianMixture(n_components = 6, max_iter = 2000, covariance_type='diag',n_init = 3)\n",
    "# open_gmm.fit(openFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialise the subplot function using number of rows and columns\n",
    "# figure, axis = plt.subplots(2, 2)\n",
    "\n",
    "# # For Sine Function\n",
    "# axis[0, 0].plot(features['Michael'],'ro')\n",
    "# axis[0, 0].set_title(\"michael\")\n",
    "\n",
    "# # For Cosine Function\n",
    "# axis[0, 1].plot(features['Belal'])\n",
    "# axis[0, 1].set_title(\"Belal\")\n",
    "\n",
    "# # For Tangent Function\n",
    "# axis[1, 0].plot(features['ahmed_ashraf'])\n",
    "# axis[1, 0].set_title(\"ahmed_ashraf\")\n",
    "\n",
    "# # For Tanh Function\n",
    "# axis[1, 1].plot(features['others'])\n",
    "# axis[1, 1].set_title(\"others\")\n",
    "\n",
    "# names = ['group_a', 'group_b', 'group_c']\n",
    "# values = [1, 10, 100]\n",
    "\n",
    "# # Combine all the operations and display\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in models.items():\n",
    "    pickle.dump(val,open(key+'.gmm','wb'))\n",
    "# pickle.dump(michael_gmm,open('mayar.gmm','wb'))\n",
    "# pickle.dump(belal_gmm,open('mina.gmm','wb'))\n",
    "# pickle.dump(ahmed_gmm,open('magdy.gmm','wb'))\n",
    "# pickle.dump(others_gmm,open('mostafa.gmm','wb'))\n",
    "# pickle.dump(open_gmm,open('open.gmm','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.12283146e+00 -3.11029332e+00 -2.45874201e-02 ...  1.25697762e+00\n",
      "   8.79253506e-02 -7.26827838e-01]\n",
      " [-2.10684288e+00 -3.06846582e+00 -2.58497052e-02 ...  1.82507820e-01\n",
      "   6.11102389e-01 -3.60049720e-01]\n",
      " [-2.12182750e+00 -3.25984272e+00 -4.99748252e-01 ... -7.97423266e-01\n",
      "   5.04621724e-01  3.42559153e-02]\n",
      " ...\n",
      " [-1.02747483e+00 -5.12916721e-01  1.32106030e+00 ... -2.59034201e-01\n",
      "   5.48249644e-01  1.32213086e+00]\n",
      " [-8.87451273e-01 -1.35024487e-01  1.92176272e+00 ... -2.20977113e-01\n",
      "   1.05990225e+00  8.35080524e-01]\n",
      " [-8.92624005e-01  3.06256969e-03  2.09456893e+00 ... -4.74581214e-01\n",
      "   6.25063010e-01  1.14822987e+00]]\n",
      "198\n",
      "20\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\somakiko\\AppData\\Local\\Temp\\ipykernel_4564\\1574464318.py:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sentenceFeatures = np.array([chroma_stft,rmse,spec_cent,spec_bw,rolloff,zcr])\n"
     ]
    }
   ],
   "source": [
    "test = extract_features('./testing_set/sample.wav')\n",
    "print(test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\SBME\\3rd year\\DSP\\repo final\\audio-recognition-2\\Ahmed_Belal_Micheal\\project_2.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20year/DSP/repo%20final/audio-recognition-2/Ahmed_Belal_Micheal/project_2.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m modelName,model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mitems():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20year/DSP/repo%20final/audio-recognition-2/Ahmed_Belal_Micheal/project_2.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodelName\u001b[39m}\u001b[39;00m\u001b[39m scored \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mscore(test)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\somakiko\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\mixture\\_base.py:382\u001b[0m, in \u001b[0;36mBaseMixture.score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscore\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    366\u001b[0m     \u001b[39m\"\"\"Compute the per-sample average log-likelihood of the given data X.\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \n\u001b[0;32m    368\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39m        Log-likelihood of `X` under the Gaussian mixture model.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscore_samples(X)\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\somakiko\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\mixture\\_base.py:361\u001b[0m, in \u001b[0;36mBaseMixture.score_samples\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[39m\"\"\"Compute the log-likelihood of each sample.\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \n\u001b[0;32m    349\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39m    Log-likelihood of each sample in `X` under the current model.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    360\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 361\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    363\u001b[0m \u001b[39mreturn\u001b[39;00m logsumexp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_estimate_weighted_log_prob(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\somakiko\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\somakiko\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:852\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    850\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    851\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 852\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    853\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    854\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    855\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    856\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "for modelName,model in models.items():\n",
    "    print(f'{modelName} scored {model.score(test)}')\n",
    "# scores_1=np.array(open_gmm.score(test))\n",
    "# scores_2=np.array(michael_gmm.score(test))\n",
    "# scores_3=np.array(belal_gmm.score(test))\n",
    "# scores_4=np.array(ahmed_gmm.score(test))\n",
    "# scores_5=np.array(others_gmm.score(test))\n",
    "\n",
    "# print(scores_1)\n",
    "# print(scores_2)\n",
    "# print(scores_3)\n",
    "# print(scores_4)\n",
    "# print(scores_5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5678e8a52b60d1c9b219a1d69295526afac88649727b7a024a2e135df0fa438d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
